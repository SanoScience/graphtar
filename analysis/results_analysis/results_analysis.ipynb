{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27bf5b0d-abde-4a76-8fdb-84c1ef6cc975",
   "metadata": {},
   "source": [
    "#### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d90b74a-b6d6-4b9d-b23d-dddc3e003a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [418, 627, 960, 426, 16, 523, 708, 541, 747, 897, 714, 127, 657, 662, 284, 595, 852, 734, 136, 394,\n",
    "             321, 200, 502, 786, 817, 264, 929, 407, 515, 411]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51446911-a6d3-41a8-bea0-887fe5a918ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import roc_curve, accuracy_score, balanced_accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "import numpy as np\n",
    "from typing import Dict\n",
    "from statistics import mean, stdev\n",
    "\n",
    "def get_df(path: str, seed) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path, header=None)\n",
    "    df = df.rename(columns={0: \"inference\", 1: \"ground_truth\"})\n",
    "    df[\"seed\"] = seed\n",
    "    df[\"ground_truth\"] = df[\"ground_truth\"].astype(float)\n",
    "    return df\n",
    "\n",
    "def get_best_treshold(ground_truths: np.ndarray, inferences: np.ndarray):\n",
    "    fpr, tpr, tresholds = roc_curve(ground_truths, inferences)\n",
    "    return tresholds[np.argmin(np.abs(tpr + fpr - 1))]\n",
    "\n",
    "def get_predictions(inferences: np.ndarray, treshold):\n",
    "    return np.where(inferences >= treshold, 1, 0)\n",
    "\n",
    "def get_scores(results: Dict):\n",
    "    datasets = [\"deepmirtar\", \"miraw\", \"mirtarraw\"]\n",
    "    metrics = {\"balanced_acc\": balanced_accuracy_score, \"f1\": f1_score, \"precision\": precision_score, \"recall\": recall_score, \"auc\": roc_auc_score}\n",
    "    for dataset in datasets:\n",
    "        metric_scores = {key:[] for key in metrics.keys()}\n",
    "        for seed in seeds:\n",
    "            df = results[dataset]\n",
    "            df = df[df[\"seed\"]==seed]\n",
    "            ground_truths = df[\"ground_truth\"].to_numpy()\n",
    "            inferences = df[\"inference\"].to_numpy()\n",
    "            prediction_treshold = get_best_treshold(ground_truths, inferences)\n",
    "            predictions = get_predictions(inferences, prediction_treshold)\n",
    "            for key, metric in metrics.items():\n",
    "                score = metric(ground_truths, predictions)\n",
    "                metric_scores[key].append(score)\n",
    "        print_metric_scores(metric_scores, dataset)\n",
    "\n",
    "def print_metric_scores(metric_scores, dataset, graph_layer=None):\n",
    "    print(\"##########################\")\n",
    "    if graph_layer:\n",
    "        print(\"Dataset: {}, Graph layer: {}\".format(dataset, graph_layer))\n",
    "    else:\n",
    "        print(\"Dataset: {}\".format(dataset))\n",
    "    for key, scores in metric_scores.items():\n",
    "        print(\"Metric: {}, mean: {}, min: {}, max: {}, std: {}\".format(key, mean(scores), min(scores), max(scores), stdev(scores)))\n",
    "        \n",
    "def get_graph_scores(results: Dict):\n",
    "    datasets = [\"deepmirtar\", \"miraw\", \"mirtarraw\"]\n",
    "    metrics = {\"balanced_acc\": balanced_accuracy_score, \"f1\": f1_score, \"precision\": precision_score, \"recall\": recall_score, \"auc\": roc_auc_score}\n",
    "    gnn_layer_type = [\"GCN\", \"GAT\", \"GRAPHSAGE\"]\n",
    "    for dataset in datasets:\n",
    "        for gnn_layer in gnn_layer_type:\n",
    "            metric_scores = {key:[] for key in metrics.keys()}\n",
    "            for seed in seeds:\n",
    "                df = results[dataset][gnn_layer]\n",
    "                df = df[df[\"seed\"]==seed]\n",
    "                ground_truths = df[\"ground_truth\"].to_numpy()\n",
    "                inferences = df[\"inference\"].to_numpy()\n",
    "                prediction_treshold = get_best_treshold(ground_truths, inferences)\n",
    "                predictions = get_predictions(inferences, prediction_treshold)\n",
    "                for key, metric in metrics.items():\n",
    "                    score = metric(ground_truths, predictions)\n",
    "                    metric_scores[key].append(score)\n",
    "            print_metric_scores(metric_scores, dataset, gnn_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fdf374-1585-448b-86b6-b7f7f8701d45",
   "metadata": {},
   "source": [
    "### miraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bec76150-7ddb-451c-879d-b13a308c5590",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "        (128, \"deepmirtar\", 0.001),\n",
    "        (64, \"miraw\", 0.001),\n",
    "        (128, \"mirtarraw\", 0.001),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2083759-a86f-4875-b537-028d3bc4309b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for config in configs:\n",
    "    df_list = []\n",
    "    batch_size, dataset, lr = config\n",
    "    for seed in seeds:\n",
    "        filename = \"../../experiments/miraw/results/miraw_ann_{}_config_{}_{}_{}.csv\".format(dataset, batch_size, seed, lr)\n",
    "        df = get_df(filename, seed)\n",
    "        df_list.append(df)\n",
    "    concatenated_dfs = pd.concat(df_list, axis=0)\n",
    "    results[dataset] = concatenated_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9acf624b-bfd2-4e57-af33-888c8227dc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################\n",
      "Dataset: deepmirtar\n",
      "Metric: balanced_acc, mean: 0.9022384999713331, min: 0.8798661064657183, max: 0.9270610365181293, std: 0.012371089815869247\n",
      "Metric: f1, mean: 0.9024761293232006, min: 0.8763250883392227, max: 0.9257641921397379, std: 0.01342717196645826\n",
      "Metric: precision, mean: 0.9024758523794282, min: 0.8717047451669596, max: 0.9250814332247557, std: 0.015528950326991852\n",
      "Metric: recall, mean: 0.9024977387827366, min: 0.8809946714031972, max: 0.9281961471103327, std: 0.011787962198240558\n",
      "Metric: auc, mean: 0.9022384999713331, min: 0.8798661064657183, max: 0.9270610365181293, std: 0.012371089815869228\n",
      "##########################\n",
      "Dataset: miraw\n",
      "Metric: balanced_acc, mean: 0.9378301597007878, min: 0.9319091452698178, max: 0.9455263273475778, std: 0.0031461380635202665\n",
      "Metric: f1, mean: 0.9382810025008321, min: 0.9321053758834869, max: 0.9456244689889549, std: 0.0031787374010597857\n",
      "Metric: precision, mean: 0.9387382037108534, min: 0.9317062727467351, max: 0.9460537363560033, std: 0.003323773721935239\n",
      "Metric: recall, mean: 0.9378250729106609, min: 0.9315967810249894, max: 0.9454236568273519, std: 0.003156679993903169\n",
      "Metric: auc, mean: 0.9378301597007878, min: 0.9319091452698177, max: 0.9455263273475779, std: 0.0031461380635202734\n",
      "##########################\n",
      "Dataset: mirtarraw\n",
      "Metric: balanced_acc, mean: 0.9280589330516992, min: 0.9211162577623944, max: 0.9379539749729073, std: 0.003916898304668758\n",
      "Metric: f1, mean: 0.9279946853516009, min: 0.9214935375777883, max: 0.9362017804154302, std: 0.0035856165638557826\n",
      "Metric: precision, mean: 0.9278922916553073, min: 0.9212827988338192, max: 0.9347014925373134, std: 0.0034694915965190268\n",
      "Metric: recall, mean: 0.928099201498569, min: 0.9210526315789473, max: 0.9380574826560951, std: 0.003963382706316985\n",
      "Metric: auc, mean: 0.9280589330516992, min: 0.9211162577623944, max: 0.9379539749729074, std: 0.0039168983046687705\n"
     ]
    }
   ],
   "source": [
    "get_scores(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b08ea7-11bf-44ea-84b3-67c6d917b0c5",
   "metadata": {},
   "source": [
    "### deepmirtar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1bc1e27-ec07-40cc-9fd9-e708902f8abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "        (512, \"deepmirtar\", 0.001),\n",
    "        (512, \"miraw\", 0.001),\n",
    "        (256, \"mirtarraw\", 0.001),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5baf47a9-a883-4881-99d8-0334c06cb8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for config in configs:\n",
    "    df_list = []\n",
    "    batch_size, dataset, lr = config\n",
    "    for seed in seeds:\n",
    "        filename = \"../../experiments/deepmirtar/results/deepmirtar_ann_{}_config_{}_{}_{}.csv\".format(dataset, batch_size, seed, lr)\n",
    "        df = get_df(filename, seed)\n",
    "        df_list.append(df)\n",
    "    concatenated_dfs = pd.concat(df_list, axis=0)\n",
    "    results[dataset] = concatenated_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5dbe5fe-2d8c-44f2-b4d8-11f497322193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################\n",
      "Dataset: deepmirtar\n",
      "Metric: balanced_acc, mean: 0.8153637961403988, min: 0.7948390559205483, max: 0.8429279614032604, std: 0.011130223476319341\n",
      "Metric: f1, mean: 0.8159083393029651, min: 0.7964444444444445, max: 0.8460891505466779, std: 0.01133108582223124\n",
      "Metric: precision, mean: 0.8165716806466606, min: 0.7901234567901234, max: 0.8496621621621622, std: 0.013031275876639863\n",
      "Metric: recall, mean: 0.8152904260000569, min: 0.7953020134228188, max: 0.8425460636515912, std: 0.011136657216198468\n",
      "Metric: auc, mean: 0.8153637961403988, min: 0.7948390559205483, max: 0.8429279614032603, std: 0.011130223476319317\n",
      "##########################\n",
      "Dataset: miraw\n",
      "Metric: balanced_acc, mean: 0.87501129417586, min: 0.8693473337779309, max: 0.8846685406206235, std: 0.00370728561662137\n",
      "Metric: f1, mean: 0.8758670363825928, min: 0.8698351530721473, max: 0.8848768054375532, std: 0.0036435589216141486\n",
      "Metric: precision, mean: 0.8767010081382495, min: 0.8690909090909091, max: 0.8850647971106862, std: 0.003943576808265961\n",
      "Metric: recall, mean: 0.8750378313627012, min: 0.869382612347753, max: 0.8846888936079847, std: 0.0037259515414707314\n",
      "Metric: auc, mean: 0.87501129417586, min: 0.8693473337779309, max: 0.8846685406206234, std: 0.0037072856166213758\n",
      "##########################\n",
      "Dataset: mirtarraw\n",
      "Metric: balanced_acc, mean: 0.8268319748791598, min: 0.8181799243371164, max: 0.8350161143424126, std: 0.004147162806615169\n",
      "Metric: f1, mean: 0.8266488625631639, min: 0.8148873653281097, max: 0.8334937439846006, std: 0.0043718864383671474\n",
      "Metric: precision, mean: 0.8264802130979781, min: 0.8117073170731708, max: 0.8342117872544322, std: 0.005526385570488202\n",
      "Metric: recall, mean: 0.8268286901951584, min: 0.8180924287118977, max: 0.8349561830574489, std: 0.004130678938517381\n",
      "Metric: auc, mean: 0.8268319748791598, min: 0.8181799243371164, max: 0.8350161143424126, std: 0.004147162806615151\n"
     ]
    }
   ],
   "source": [
    "get_scores(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44728ba-2085-4d41-9000-9e16e72076d8",
   "metadata": {},
   "source": [
    "### mitar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bacd35c-ab80-4085-8aa2-4e9813516ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "        (16, \"deepmirtar\", 0.001),\n",
    "        (64, \"miraw\", 0.001),\n",
    "        (64, \"mirtarraw\", 0.001),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ffcf0d4-5e1e-4eeb-bcf4-bce34de0c8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for config in configs:\n",
    "    df_list = []\n",
    "    batch_size, dataset, lr = config\n",
    "    for seed in seeds:\n",
    "        filename = \"../../experiments/mitar/results/mitar_net_{}_config_{}_{}_{}.csv\".format(dataset, batch_size, seed, lr)\n",
    "        df = get_df(filename, seed)\n",
    "        df_list.append(df)\n",
    "    concatenated_dfs = pd.concat(df_list, axis=0)\n",
    "    results[dataset] = concatenated_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97fb709c-d274-4489-b5dc-f20548387ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################\n",
      "Dataset: deepmirtar\n",
      "Metric: balanced_acc, mean: 0.9274428608712387, min: 0.8944088203543008, max: 0.9502275514053952, std: 0.011969235007181955\n",
      "Metric: f1, mean: 0.9277094842802632, min: 0.897071129707113, max: 0.9506802721088435, std: 0.01173023783166883\n",
      "Metric: precision, mean: 0.9279809210795459, min: 0.8993288590604027, max: 0.9522998296422487, std: 0.011950042354267554\n",
      "Metric: recall, mean: 0.9274481229321292, min: 0.8948247078464107, max: 0.9490662139219015, std: 0.011909313053262352\n",
      "Metric: auc, mean: 0.9274428608712387, min: 0.8944088203543008, max: 0.950227551405395, std: 0.01196923500718194\n",
      "##########################\n",
      "Dataset: miraw\n",
      "Metric: balanced_acc, mean: 0.9393835730591168, min: 0.9315852091439464, max: 0.9444615165129804, std: 0.0035676128967912593\n",
      "Metric: f1, mean: 0.9398157333683317, min: 0.9322447248436009, max: 0.94529448752882, std: 0.0037150969743315132\n",
      "Metric: precision, mean: 0.9402676854276337, min: 0.9325413661434027, max: 0.9460876861757919, std: 0.003970567422217899\n",
      "Metric: recall, mean: 0.9393650120087838, min: 0.931714404317144, max: 0.9445026178010472, std: 0.00355145817416264\n",
      "Metric: auc, mean: 0.9393835730591168, min: 0.9315852091439464, max: 0.9444615165129803, std: 0.0035676128967912497\n",
      "##########################\n",
      "Dataset: mirtarraw\n",
      "Metric: balanced_acc, mean: 0.9103817708571854, min: 0.8869682330429752, max: 0.923760074711133, std: 0.00831706630983117\n",
      "Metric: f1, mean: 0.9102377761653061, min: 0.8826173826173827, max: 0.9245417757676743, std: 0.008850213765395945\n",
      "Metric: precision, mean: 0.9101485289862511, min: 0.8782306163021869, max: 0.9252024773701762, std: 0.009558745111071876\n",
      "Metric: recall, mean: 0.9103308230220567, min: 0.8870481927710844, max: 0.9238820171265462, std: 0.00828974048787743\n",
      "Metric: auc, mean: 0.9103817708571854, min: 0.8869682330429753, max: 0.9237600747111331, std: 0.008317066309831167\n"
     ]
    }
   ],
   "source": [
    "get_scores(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810ae895-0375-4700-8a24-3ff3d0c49b5e",
   "metadata": {},
   "source": [
    "### graphtar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11e64bf3-8089-4220-9e22-8d371e96d434",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "        (\"GCN\", 128, \"deepmirtar\", 128, 3, \"MAX\", 512, 2, 0.4, 0.001),\n",
    "        (\"GCN\", 64, \"miraw\", 128, 3, \"MAX\", 512, 2, 0.4, 0.001),\n",
    "        (\"GCN\", 64, \"mirtarraw\", 128, 3, \"MAX\", 512, 2, 0.4, 0.001),\n",
    "        (\"GAT\",128, \"deepmirtar\", 256, 5, \"ADD\", 128, 2, 0.4, 0.001),\n",
    "        (\"GAT\", 512, \"miraw\", 256, 5, \"ADD\", 128, 2, 0.4, 0.001),\n",
    "        (\"GAT\", 512, \"mirtarraw\", 256, 5, \"ADD\", 128, 2, 0.4, 0.001),\n",
    "        (\"GRAPHSAGE\", 128, \"deepmirtar\", 256, 5, \"ADD\", 256, 3, 0.4, 0.001),\n",
    "        (\"GRAPHSAGE\", 32, \"miraw\", 256, 5, \"ADD\", 256, 3, 0.4, 0.001),\n",
    "        (\"GRAPHSAGE\", 256, \"mirtarraw\", 256, 5, \"ADD\", 256, 3, 0.4, 0.001),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c6c80c3-6f3f-48ee-b40d-4e8d28653412",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for config in configs:\n",
    "    df_list = []\n",
    "    gnn_layer_type, batch_size, dataset_type, graph_layer_size, n_gnn_layers, global_pooling, fc_layer_size, n_fc_layers, dropout_rate, lr = config\n",
    "    for seed in seeds:\n",
    "        filename = \"../../experiments/graphtar/results/{}_{}_{}.csv\".format(gnn_layer_type, dataset_type, seed)\n",
    "        df = get_df(filename, seed)\n",
    "        df_list.append(df)\n",
    "    concatenated_dfs = pd.concat(df_list, axis=0)\n",
    "    if results.get(dataset, None) is None:\n",
    "        results[dataset_type] = {}\n",
    "    results[dataset_type][gnn_layer_type] = concatenated_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a1f638a-0749-44fc-a282-b662e86e2ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################\n",
      "Dataset: deepmirtar, Graph layer: GCN\n",
      "Metric: balanced_acc, mean: 0.904285743881202, min: 0.8678138558762498, max: 0.9338432184396159, std: 0.013823708520151518\n",
      "Metric: f1, mean: 0.9046144564522566, min: 0.869047619047619, max: 0.9355648535564853, std: 0.01403123187542384\n",
      "Metric: precision, mean: 0.9046450320458003, min: 0.8705281090289608, max: 0.9347826086956522, std: 0.014383583930276276\n",
      "Metric: recall, mean: 0.9045960529857009, min: 0.8675721561969439, max: 0.9363484087102177, std: 0.014080622984177291\n",
      "Metric: auc, mean: 0.904285743881202, min: 0.8678138558762498, max: 0.933843218439616, std: 0.013823708520151556\n",
      "##########################\n",
      "Dataset: deepmirtar, Graph layer: GAT\n",
      "Metric: balanced_acc, mean: 0.9221780280890802, min: 0.878960943257185, max: 0.949346202845212, std: 0.014594619586487109\n",
      "Metric: f1, mean: 0.9223326015161759, min: 0.8804071246819339, max: 0.9505448449287511, std: 0.015046976758207795\n",
      "Metric: precision, mean: 0.9226114047326192, min: 0.8811544991511036, max: 0.9513422818791947, std: 0.01564594934226772\n",
      "Metric: recall, mean: 0.9220640348886007, min: 0.8796610169491526, max: 0.949748743718593, std: 0.014755815707670332\n",
      "Metric: auc, mean: 0.9221780280890802, min: 0.878960943257185, max: 0.949346202845212, std: 0.014594619586487086\n",
      "##########################\n",
      "Dataset: deepmirtar, Graph layer: GRAPHSAGE\n",
      "Metric: balanced_acc, mean: 0.9154182898233006, min: 0.8738321062466474, max: 0.9390643447461628, std: 0.017762318755571025\n",
      "Metric: f1, mean: 0.9156152787951731, min: 0.8718395815170009, max: 0.9426957223567393, std: 0.018250817863221382\n",
      "Metric: precision, mean: 0.9157462283787847, min: 0.8680555555555556, max: 0.9449838187702265, std: 0.019158384561772455\n",
      "Metric: recall, mean: 0.9154952555102946, min: 0.8754325259515571, max: 0.9404186795491143, std: 0.01758691417519912\n",
      "Metric: auc, mean: 0.9154182898233006, min: 0.8738321062466473, max: 0.939064344746163, std: 0.017762318755571063\n",
      "##########################\n",
      "Dataset: miraw, Graph layer: GCN\n",
      "Metric: balanced_acc, mean: 0.9355784110005231, min: 0.9281839929240527, max: 0.9457376664195389, std: 0.004066030144545644\n",
      "Metric: f1, mean: 0.9360373232171595, min: 0.9284427011555179, max: 0.946259220231823, std: 0.004183975176090086\n",
      "Metric: precision, mean: 0.9365033615126186, min: 0.9287380699893956, max: 0.9466582331857474, std: 0.004381452471592022\n",
      "Metric: recall, mean: 0.9355726728999921, min: 0.9281475201356507, max: 0.9458605435011587, std: 0.00408794441544155\n",
      "Metric: auc, mean: 0.9355784110005231, min: 0.9281839929240526, max: 0.9457376664195389, std: 0.004066030144545661\n",
      "##########################\n",
      "Dataset: miraw, Graph layer: GAT\n",
      "Metric: balanced_acc, mean: 0.9479555641203898, min: 0.939461785335195, max: 0.9548906618127464, std: 0.0037438241355432504\n",
      "Metric: f1, mean: 0.9483307691755603, min: 0.9397309607033154, max: 0.9553119730185498, std: 0.0038480354987394496\n",
      "Metric: precision, mean: 0.9487104567731035, min: 0.9400296673023946, max: 0.9559164733178654, std: 0.004033060209042608\n",
      "Metric: recall, mean: 0.9479519858142079, min: 0.939432443879712, max: 0.9547082367811249, std: 0.0037339654447537383\n",
      "Metric: auc, mean: 0.9479555641203898, min: 0.939461785335195, max: 0.9548906618127465, std: 0.003743824135543252\n",
      "##########################\n",
      "Dataset: miraw, Graph layer: GRAPHSAGE\n",
      "Metric: balanced_acc, mean: 0.9398198567097464, min: 0.9315874023127076, max: 0.9456325248015649, std: 0.0035210422012672687\n",
      "Metric: f1, mean: 0.9402629920661739, min: 0.9320367825811224, max: 0.945641888339817, std: 0.0034373581848759064\n",
      "Metric: precision, mean: 0.9407111388836858, min: 0.9323324170014802, max: 0.9463722397476341, std: 0.003498409359567679\n",
      "Metric: recall, mean: 0.9398160338140585, min: 0.9317413355874894, max: 0.945531914893617, std: 0.0034837912383581114\n",
      "Metric: auc, mean: 0.9398198567097464, min: 0.9315874023127078, max: 0.9456325248015649, std: 0.003521042201267272\n",
      "##########################\n",
      "Dataset: mirtarraw, Graph layer: GCN\n",
      "Metric: balanced_acc, mean: 0.9153361833797595, min: 0.9001924280176674, max: 0.9283313247283755, std: 0.006679575152925129\n",
      "Metric: f1, mean: 0.9152384914504694, min: 0.9012610040447299, max: 0.9282964388835419, std: 0.0066954965851913255\n",
      "Metric: precision, mean: 0.9151293762027835, min: 0.9014968614196041, max: 0.9278499278499278, std: 0.006858806017778345\n",
      "Metric: recall, mean: 0.9153506984983841, min: 0.9001901140684411, max: 0.9287433798748195, std: 0.006745297678177963\n",
      "Metric: auc, mean: 0.9153361833797594, min: 0.9001924280176675, max: 0.9283313247283755, std: 0.0066795751529251145\n",
      "##########################\n",
      "Dataset: mirtarraw, Graph layer: GAT\n",
      "Metric: balanced_acc, mean: 0.9211473785892709, min: 0.9102909997022044, max: 0.9324183361039019, std: 0.005570020319764739\n",
      "Metric: f1, mean: 0.921055839924948, min: 0.9103580869983177, max: 0.9331747919143877, std: 0.005595716697677925\n",
      "Metric: precision, mean: 0.9209550140785763, min: 0.9105769230769231, max: 0.9338410280818658, std: 0.005751206002456051\n",
      "Metric: recall, mean: 0.9211591070452516, min: 0.9101393560788082, max: 0.9325095057034221, std: 0.005643800752086099\n",
      "Metric: auc, mean: 0.9211473785892709, min: 0.9102909997022044, max: 0.9324183361039019, std: 0.005570020319764727\n",
      "##########################\n",
      "Dataset: mirtarraw, Graph layer: GRAPHSAGE\n",
      "Metric: balanced_acc, mean: 0.9140694177247166, min: 0.901154541039744, max: 0.9230405871879656, std: 0.005210861252864497\n",
      "Metric: f1, mean: 0.9139688418781945, min: 0.9012256669069935, max: 0.9217221135029355, std: 0.005246792717091953\n",
      "Metric: precision, mean: 0.9138899430428751, min: 0.9014423076923077, max: 0.9239028944911298, std: 0.005546876261542537\n",
      "Metric: recall, mean: 0.9140507274822085, min: 0.9010091302258529, max: 0.9230769230769231, std: 0.0052053965005028425\n",
      "Metric: auc, mean: 0.9140694177247166, min: 0.901154541039744, max: 0.9230405871879656, std: 0.005210861252864478\n"
     ]
    }
   ],
   "source": [
    "get_graph_scores(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
